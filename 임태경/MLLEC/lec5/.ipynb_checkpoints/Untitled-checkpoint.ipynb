{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classification의 가설 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Binary Classification\n",
    "   -> 둘중의 하나를 고르는것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0또는 1로 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수를 쓰면 결과값을 0~1의 값을 가질수있다\n",
    "\n",
    "시그모이드 함수로 cost function을 구해보면 울퉁불퉁한 밥그릇 모양이나와 최소값에 도달하지못하고 local minimaze에 빠질수있다.\n",
    "\n",
    "cost(W) = 1/m t=시그마 c(H(x),y)\n",
    "\n",
    "c(H(x),y) { -log(H(x)) : y=1\n",
    "          { -log(1-H(x)) : y=0\n",
    "          \n",
    "g(z) = -log(z)      y= 1\n",
    "                    { H(x) = 1 -> cost(1) = 0\n",
    "                    { H(x) = 0 -> cost = 무한대에 도달하게됨(시스템이 잘못 예측했을경우)\n",
    "                    \n",
    "g(z) = -log(1-z)                    \n",
    "                    y=0\n",
    "                    { H(x) = 0 -> cost=0\n",
    "                    { H(x) = 1 -> cost = 무한대(시스템이 잘못 예측했을경우)\n",
    "                    \n",
    "Cost function                    \n",
    "C(H(x),y) = -ylog(H(x)) - (1-y)log(1-H(x))\n",
    "\n",
    "y=1, c = -log(H(x))    사라짐\n",
    "y=0, c =  사라짐        -1 * log(1-H(x))\n",
    "\n",
    "Minimize cost - Gradient decent algorithm\n",
    "기울기를 구함\n",
    "\n",
    "# TensorFlow로 Logistic Classification 구현하기(new)\n",
    "\n",
    "cost를 가장작게하는 w를 구하는것!\n",
    "(x축 w, y축 cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]] #0-fail, 1-pass\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) #hypothesis가 0.5보다 큰지 작은지 ex)크면 pass 작으면 fail\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9307764\n",
      "200 0.59693706\n",
      "400 0.4664837\n",
      "600 0.4104062\n",
      "800 0.38049313\n",
      "1000 0.36100116\n",
      "1200 0.34627834\n",
      "1400 0.33403608\n",
      "1600 0.32325006\n",
      "1800 0.31342345\n",
      "2000 0.30429748\n",
      "2200 0.29572764\n",
      "2400 0.28762743\n",
      "2600 0.2799407\n",
      "2800 0.27262807\n",
      "3000 0.26565945\n",
      "3200 0.25901043\n",
      "3400 0.2526605\n",
      "3600 0.24659093\n",
      "3800 0.2407855\n",
      "4000 0.23522879\n",
      "4200 0.22990681\n",
      "4400 0.22480632\n",
      "4600 0.21991523\n",
      "4800 0.21522193\n",
      "5000 0.21071582\n",
      "5200 0.20638669\n",
      "5400 0.20222533\n",
      "5600 0.19822276\n",
      "5800 0.19437079\n",
      "6000 0.19066155\n",
      "6200 0.18708777\n",
      "6400 0.18364263\n",
      "6600 0.18031967\n",
      "6800 0.17711282\n",
      "7000 0.17401649\n",
      "7200 0.17102526\n",
      "7400 0.16813411\n",
      "7600 0.16533844\n",
      "7800 0.16263357\n",
      "8000 0.16001546\n",
      "8200 0.15748012\n",
      "8400 0.15502381\n",
      "8600 0.15264297\n",
      "8800 0.1503343\n",
      "9000 0.14809474\n",
      "9200 0.14592119\n",
      "9400 0.14381094\n",
      "9600 0.14176133\n",
      "9800 0.13976975\n",
      "10000 0.13783391\n",
      "\n",
      "Hypothesis:  [[0.0259921 ]\n",
      " [0.15186763]\n",
      " [0.28126708]\n",
      " [0.7923803 ]\n",
      " [0.9462932 ]\n",
      " [0.9824462 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
